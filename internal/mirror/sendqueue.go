package mirror

import (
	"log"
	"sort"
	"sync"
)

type SendQueue struct {
	sync.Mutex

	completedEpochsUntil uint64 // Keep track of until which epoch we saw all data

	// Map of epochs that are completed, but the completedEpochsUntil could not be updated yet.
	// Should only contain epochs bigger than completedEpochsUntil. Elements directly
	// following completedEpochsUntil will be removed and cleaned up form this map
	// For this to work all epoch should be consecutive
	epochsCompleted map[uint64]interface{}

	requestsQueued []*Request // Slice with queued requests, ordered by epoch from old to new
	maxQueueSize   int
}

func MakeSendQueue(maxQueueSize int) *SendQueue {
	return &SendQueue{
		epochsCompleted:      make(map[uint64]interface{}, 0),
		completedEpochsUntil: 0, // This needs to be in sync with the epoch generated by handler.
		maxQueueSize:         maxQueueSize,
	}
}

func (s *SendQueue) Clone() *SendQueue {
	completedCopied := make(map[uint64]interface{}, 0)
	for c, _ := range s.epochsCompleted {
		completedCopied[c] = nil
	}

	return &SendQueue{
		completedEpochsUntil: s.completedEpochsUntil,
		epochsCompleted:      completedCopied,
		requestsQueued:       append([]*Request(nil), s.requestsQueued...),
		maxQueueSize:         s.maxQueueSize,
	}
}

func (s *SendQueue) AddToQueue(req *Request, targetURL string) {
	s.Lock()
	defer s.Unlock()

	if len(s.requestsQueued) >= s.maxQueueSize {
		log.Printf("Send queue for target %s exceeded %d, dropping request", targetURL, s.maxQueueSize)
		s.performCompleted(req)
		return
	}

	// Perform ordered insertion

	// Stolen from SearchInt
	i := sort.Search(len(s.requestsQueued), func(i int) bool { return s.requestsQueued[i].epoch >= req.epoch })
	// Make room
	s.requestsQueued = append(s.requestsQueued, nil)
	// Move remainder back
	copy(s.requestsQueued[i+1:], s.requestsQueued[i:])
	// Insert request
	s.requestsQueued[i] = req
}

func (s *SendQueue) NextExecuteItems() []*Request {
	s.Lock()
	defer s.Unlock()

	var result []*Request
	var newQueue []*Request = make([]*Request, 0, len(s.requestsQueued))

	// Try to find the next request that can execute, assumes
	for _, request := range s.requestsQueued {
		// Try to figure out whether the completed epoch have advanced enough for the request to be picked up.
		// We do this by extending the completedEpochsUntil with the activeRequests information (which can be parallel)
		// and the epochsCompleted map.
		var completeUntilForRequest uint64 = s.completedEpochsUntil + 1

		// Extend completion, if a request is 'active' we can regard it as completed
		for ; completeUntilForRequest < request.epoch; completeUntilForRequest++ {
			_, activeExists := request.activeRequests[completeUntilForRequest]
			_, completeExists := s.epochsCompleted[completeUntilForRequest]

			if activeExists || completeExists {
				continue
			} else {
				break
			}
		}

		if completeUntilForRequest >= request.epoch {
			// Start executing, do not add to new queue
			result = append(result, request)
		} else {
			newQueue = append(newQueue, request)
		}
	}

	s.requestsQueued = newQueue

	return result
}

func (s *SendQueue) ExecutionCompleted(req *Request) {
	// Request was executed. Remove form in flight and potentially start new work
	s.Lock()
	defer s.Unlock()

	s.performCompleted(req)
}

// This expects the lock to be held
func (s *SendQueue) performCompleted(req *Request) {
	// Mark as complete
	s.epochsCompleted[req.epoch] = nil

	// Try to move the completedUntil
	for {
		if _, ok := s.epochsCompleted[s.completedEpochsUntil+1]; ok {
			s.completedEpochsUntil++
			delete(s.epochsCompleted, s.completedEpochsUntil)
		} else {
			break
		}
	}
}
